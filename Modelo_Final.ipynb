{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Renan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "c:\\Users\\Renan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import unidecode\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.download(\"stopwords\")\n",
    "from unidecode import unidecode\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import tensorflow as tf\n",
    "\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "\n",
    "#carregando arquivo\n",
    "df = pd.read_excel(r\"D:\\Documents\\ESTUDOS\\POS GRADUACAO\\TCC\\base_nps_completa_original.xlsx\")\n",
    "\n",
    "#limpando pesquisas em outro idioma\n",
    "df = df[df['surveyId'] == 'NPS Zendesk Português']\n",
    "#removendo números\n",
    "df['comentario_NPS'] = df['comentario_NPS'].apply(lambda x: re.sub(r'\\d', '', str(x)))\n",
    "#removendo \"\\n\" dos comentários\n",
    "df['comentario_NPS'].replace(\"\\n\", '', inplace = True)\n",
    "#trocando comentários em branco ou sem letras por NONE\n",
    "df['comentario_NPS'] = df['comentario_NPS'].apply(lambda x: x if re.fullmatch(r\".*[a-zA-Z].*\", x) != None else None)\n",
    "df['comentario_NPS'].replace({'', 'NULL','nan'}, None, inplace = True)\n",
    "#filtrando apenas pesquisas com comentários\n",
    "df = df[df['comentario_NPS'].isnull() == False]\n",
    "#transformando tudo em minúsculas\n",
    "df['comentario_NPS'] = df['comentario_NPS'].apply(lambda x: x.lower())\n",
    "#filtrando apenas as colunas necessárias\n",
    "df = df[['metadata_ticket', 'resposta_NPS', 'rqt_tipocliente', 'comentario_NPS']]\n",
    "\n",
    "#separando dataframes por tipo de ticket\n",
    "df_internos = df[df['rqt_tipocliente'] == 'INTERNO']\n",
    "df_externos = df[df['rqt_tipocliente'] != 'INTERNO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_cleaning(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    text = re.sub(r'\\[[^]]*\\]', '', soup.get_text())\n",
    "    text = unidecode(text)\n",
    "    pattern = r\"[^a-zA-Z0-9\\s,']\"\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "def to_sentiment(rating):\n",
    "  rating = int(rating)\n",
    "  if rating < 5:\n",
    "    return 0\n",
    "  elif rating == 10:\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renan\\AppData\\Local\\Temp\\ipykernel_9384\\488764235.py:2: MarkupResemblesLocatorWarning:\n",
      "\n",
      "The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.rename(columns={'comentario_NPS': 'sentence'}, inplace=True)\n",
    "\n",
    "df['sentiment'] = df.resposta_NPS.apply(to_sentiment)\n",
    "\n",
    "df['Cleaned_sentence'] = df['sentence'].apply(text_cleaning).tolist()\n",
    "\n",
    "#estratificando manualmente\n",
    "auxdf0 = df[df['sentiment']==0]\n",
    "auxdf1 = df[df['sentiment']==1].sample(n=len(auxdf0), random_state=42)\n",
    "final_df = pd.concat([auxdf0, auxdf1], ignore_index=True)\n",
    "\n",
    "\n",
    "final_df['sentiment'] = final_df['sentiment'].astype(np.int64)\n",
    "final_df = final_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "remaining_df = df[~df['metadata_ticket'].isin(final_df['metadata_ticket'])]\n",
    "\n",
    "train_df, test_df = train_test_split(final_df, test_size=0.3)\n",
    "\n",
    "# Training data\n",
    "#Reviews = \"[CLS] \" +train_df['Cleaned_sentence'] + \"[SEP]\"\n",
    "Reviews = train_df['Cleaned_sentence']\n",
    "Target = train_df['sentiment']\n",
    " \n",
    "# Test data\n",
    "#test_reviews =  \"[CLS] \" +test_df['Cleaned_sentence'] + \"[SEP]\"\n",
    "test_reviews = test_df['Cleaned_sentence']\n",
    "test_targets = test_df['sentiment']\n",
    "\n",
    "x_val, x_test, y_val, y_test = train_test_split(test_reviews,\n",
    "                                                    test_targets,\n",
    "                                                    test_size=0.5, \n",
    "                                                    stratify = test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some layers of TFBertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier', 'bert/pooler/dense/bias:0', 'bert/pooler/dense/kernel:0']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#aplicando a tokenizacao em portugues com BERTimbau\n",
    "tokenizer = BertTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased', do_lower_case=True)\n",
    "\n",
    "max_len= 175\n",
    "# Tokenize and encode the sentences\n",
    "X_train_encoded = tokenizer.batch_encode_plus(Reviews.tolist(),\n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors='tf')\n",
    " \n",
    "X_val_encoded = tokenizer.batch_encode_plus(x_val.tolist(), \n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors='tf')\n",
    " \n",
    "X_test_encoded = tokenizer.batch_encode_plus(x_test.tolist(), \n",
    "                                              padding=True, \n",
    "                                              truncation=True,\n",
    "                                              max_length = max_len,\n",
    "                                              return_tensors='tf')\n",
    "\n",
    "#criando modelo\n",
    "model = TFBertForSequenceClassification.from_pretrained('neuralmind/bert-base-portuguese-cased', num_labels=2)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.SparseCategoricalAccuracy('accuracy')\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[metric])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "93/93 [==============================] - 902s 10s/step - loss: 0.2092 - accuracy: 0.9273 - val_loss: 0.1362 - val_accuracy: 0.9669\n",
      "Epoch 2/3\n",
      "93/93 [==============================] - 886s 10s/step - loss: 0.0721 - accuracy: 0.9784 - val_loss: 0.1279 - val_accuracy: 0.9716\n",
      "Epoch 3/3\n",
      "93/93 [==============================] - 879s 9s/step - loss: 0.0471 - accuracy: 0.9875 - val_loss: 0.1180 - val_accuracy: 0.9748\n"
     ]
    }
   ],
   "source": [
    "#treinando\n",
    "history = model.fit(\n",
    "    [X_train_encoded['input_ids'], X_train_encoded['token_type_ids'], X_train_encoded['attention_mask']],\n",
    "    Target,\n",
    "    validation_data=(\n",
    "      [X_val_encoded['input_ids'], X_val_encoded['token_type_ids'], X_val_encoded['attention_mask']],y_val),\n",
    "    batch_size=32,\n",
    "    epochs=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 55s 3s/step - loss: 0.1045 - accuracy: 0.9779\n",
      "Test loss: 0.10454543679952621, Test accuracy: 0.9779179692268372\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(\n",
    "    [X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']],\n",
    "    y_test\n",
    ")\n",
    "print(f'Test loss: {test_loss}, Test accuracy: {test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = 'D:\\Documents\\ESTUDOS\\POS GRADUACAO\\TCC'\n",
    "# Save tokenizer\n",
    "tokenizer.save_pretrained(path +'/Tokenizer2')\n",
    " \n",
    "# Save model\n",
    "model.save_pretrained(path +'/Model2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Some layers from the model checkpoint at D:\\Documents\\ESTUDOS\\POS GRADUACAO\\TCC\\LeIA-master/Model2 were not used when initializing TFBertForSequenceClassification: ['dropout_75']\n",
      "- This IS expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertForSequenceClassification were initialized from the model checkpoint at D:\\Documents\\ESTUDOS\\POS GRADUACAO\\TCC\\LeIA-master/Model2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(path +'/Tokenizer2')\n",
    " \n",
    "# Load model\n",
    "bert_model = TFBertForSequenceClassification.from_pretrained(path +'/Model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 56s 3s/step\n",
      "Predicted Label : ['positive', 'positive', 'positive', 'Negative', 'Negative', 'positive', 'Negative', 'positive', 'positive', 'positive']\n",
      "Actual Label    : ['positive', 'positive', 'positive', 'Negative', 'Negative', 'positive', 'Negative', 'positive', 'positive', 'positive']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pred = bert_model.predict(\n",
    "    [X_test_encoded['input_ids'], X_test_encoded['token_type_ids'], X_test_encoded['attention_mask']])\n",
    " \n",
    "# pred is of type TFSequenceClassifierOutput\n",
    "logits = pred.logits\n",
    " \n",
    "# Use argmax along the appropriate axis to get the predicted labels\n",
    "pred_labels = tf.argmax(logits, axis=1)\n",
    " \n",
    "# Convert the predicted labels to a NumPy array\n",
    "pred_labels = pred_labels.numpy()\n",
    " \n",
    "label = {\n",
    "    1: 'positive',\n",
    "    0: 'Negative'\n",
    "}\n",
    " \n",
    "# Map the predicted labels to their corresponding strings using the label dictionary\n",
    "pred_labels = [label[i] for i in pred_labels]\n",
    "Actual = [label[i] for i in y_test]\n",
    " \n",
    "print('Predicted Label :', pred_labels[:10])\n",
    "print('Actual Label    :', Actual[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    Negative       0.97      0.99      0.98       315\n",
      "    positive       0.99      0.97      0.98       319\n",
      "\n",
      "    accuracy                           0.98       634\n",
      "   macro avg       0.98      0.98      0.98       634\n",
      "weighted avg       0.98      0.98      0.98       634\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report: \\n\", classification_report(Actual, pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Get_sentiment(Review, Tokenizer=bert_tokenizer, Model=bert_model):\n",
    "    # Convert Review to a list if it's not already a list\n",
    "    if not isinstance(Review, list):\n",
    "        Review = [Review]\n",
    " \n",
    "    Input_ids, Token_type_ids, Attention_mask = Tokenizer.batch_encode_plus(Review,\n",
    "                                                                             padding=True,\n",
    "                                                                             truncation=True,\n",
    "                                                                             max_length=128,\n",
    "                                                                             return_tensors='tf').values()\n",
    "    prediction = Model.predict([Input_ids, Token_type_ids, Attention_mask])\n",
    " \n",
    "    # Use argmax along the appropriate axis to get the predicted labels\n",
    "    pred_labels = tf.argmax(prediction.logits, axis=1)\n",
    " \n",
    "    # Convert the TensorFlow tensor to a NumPy array and then to a list to get the predicted sentiment labels\n",
    "    pred_labels = [label[i] for i in pred_labels.numpy().tolist()]\n",
    "    return pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aplicando o modelo em cada um dos comentários que sobraram, nossos alvos\n",
    "remaining_df['predicted'] = remaining_df['Cleaned_sentence'].apply(lambda x: Get_sentiment(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_df.to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "validacao = pd.read_excel('output.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment2(rating):\n",
    "  rating = int(rating)\n",
    "  if rating < 7:\n",
    "    return 'Detrator'\n",
    "  elif rating > 8:\n",
    "    return 'Promotor'\n",
    "  else:\n",
    "    return 'Neutro'\n",
    "  \n",
    "validacao['sentiment'] = validacao.resposta_NPS.apply(to_sentiment2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>['Negative']</th>\n",
       "      <th>['positive']</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Detrator</th>\n",
       "      <td>567</td>\n",
       "      <td>31</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutro</th>\n",
       "      <td>533</td>\n",
       "      <td>357</td>\n",
       "      <td>890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Promotor</th>\n",
       "      <td>705</td>\n",
       "      <td>10995</td>\n",
       "      <td>11700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1805</td>\n",
       "      <td>11383</td>\n",
       "      <td>13188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  ['Negative']  ['positive']    All\n",
       "Actual                                      \n",
       "Detrator            567            31    598\n",
       "Neutro              533           357    890\n",
       "Promotor            705         10995  11700\n",
       "All                1805         11383  13188"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validacao\n",
    "\n",
    "y_actu = pd.Series(validacao['sentiment'].to_list(), name='Actual')\n",
    "y_pred = pd.Series(validacao['predicted'].to_list(), name='Predicted')\n",
    "#df_confusion = pd.crosstab(y_actu, y_pred)\n",
    "\n",
    "df_confusion = pd.crosstab(y_actu, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "df_confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predicted</th>\n",
       "      <th>resposta_NPS</th>\n",
       "      <th>tipocliente</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"12\" valign=\"top\">['Negative']</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">6</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">['positive']</th>\n",
       "      <th>5</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">7</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">8</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">9</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">10</th>\n",
       "      <th>EXTERNO</th>\n",
       "      <td>7840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INTERNO</th>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       predicted\n",
       "predicted    resposta_NPS tipocliente           \n",
       "['Negative'] 5            EXTERNO            349\n",
       "                          INTERNO             13\n",
       "             6            EXTERNO            198\n",
       "                          INTERNO              7\n",
       "             7            EXTERNO            236\n",
       "                          INTERNO             14\n",
       "             8            EXTERNO            268\n",
       "                          INTERNO             15\n",
       "             9            EXTERNO            234\n",
       "                          INTERNO             13\n",
       "             10           EXTERNO            430\n",
       "                          INTERNO             28\n",
       "['positive'] 5            EXTERNO             15\n",
       "             6            EXTERNO             16\n",
       "             7            EXTERNO             64\n",
       "                          INTERNO              1\n",
       "             8            EXTERNO            280\n",
       "                          INTERNO             12\n",
       "             9            EXTERNO            833\n",
       "                          INTERNO            306\n",
       "             10           EXTERNO           7840\n",
       "                          INTERNO           2016"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def resumidor(rating):\n",
    "  if rating == 'INTERNO':\n",
    "    return 'INTERNO'\n",
    "  else:\n",
    "    return 'EXTERNO'\n",
    "  \n",
    "validacao['tipocliente'] = validacao.rqt_tipocliente.apply(resumidor)\n",
    "\n",
    "pd.DataFrame(validacao.groupby(['predicted','resposta_NPS', 'tipocliente'])['predicted'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_df.to_excel(\"Resultados_Finais.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
